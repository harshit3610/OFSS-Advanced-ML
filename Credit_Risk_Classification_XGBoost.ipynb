{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Risk Classification- XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfD8NtSbqtyB",
        "outputId": "c3fc5c49-cec8-46e9-a325-b442f3e564fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCs8GPLdtAfz",
        "outputId": "a12f9d2a-779b-4162-e2af-d3ca39561259"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_pn1ingLqu4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score,recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from math import log, sqrt\n",
        "%matplotlib inline "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1IVmhNaL5Ra"
      },
      "source": [
        "credit_df = pd.read_csv(\"/content/drive/MyDrive/DataSets/creditcard.csv\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CyFjbnBL7Qi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "4441251b-fbcb-4b73-c062-e1aec21b3ab8"
      },
      "source": [
        "credit_df.describe().round(2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "      <td>284807.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>88.35</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.15</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.52</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.38</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.10</td>\n",
              "      <td>1.09</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.33</td>\n",
              "      <td>250.12</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00</td>\n",
              "      <td>-56.41</td>\n",
              "      <td>-72.72</td>\n",
              "      <td>-48.33</td>\n",
              "      <td>-5.68</td>\n",
              "      <td>-113.74</td>\n",
              "      <td>-26.16</td>\n",
              "      <td>-43.56</td>\n",
              "      <td>-73.22</td>\n",
              "      <td>-13.43</td>\n",
              "      <td>-24.59</td>\n",
              "      <td>-4.80</td>\n",
              "      <td>-18.68</td>\n",
              "      <td>-5.79</td>\n",
              "      <td>-19.21</td>\n",
              "      <td>-4.50</td>\n",
              "      <td>-14.13</td>\n",
              "      <td>-25.16</td>\n",
              "      <td>-9.50</td>\n",
              "      <td>-7.21</td>\n",
              "      <td>-54.50</td>\n",
              "      <td>-34.83</td>\n",
              "      <td>-10.93</td>\n",
              "      <td>-44.81</td>\n",
              "      <td>-2.84</td>\n",
              "      <td>-10.30</td>\n",
              "      <td>-2.60</td>\n",
              "      <td>-22.57</td>\n",
              "      <td>-15.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.50</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.35</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>5.60</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>22.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.50</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.08</td>\n",
              "      <td>77.16</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>22.06</td>\n",
              "      <td>9.38</td>\n",
              "      <td>16.88</td>\n",
              "      <td>34.80</td>\n",
              "      <td>73.30</td>\n",
              "      <td>120.59</td>\n",
              "      <td>20.01</td>\n",
              "      <td>15.59</td>\n",
              "      <td>23.75</td>\n",
              "      <td>12.02</td>\n",
              "      <td>7.85</td>\n",
              "      <td>7.13</td>\n",
              "      <td>10.53</td>\n",
              "      <td>8.88</td>\n",
              "      <td>17.32</td>\n",
              "      <td>9.25</td>\n",
              "      <td>5.04</td>\n",
              "      <td>5.59</td>\n",
              "      <td>39.42</td>\n",
              "      <td>27.20</td>\n",
              "      <td>10.50</td>\n",
              "      <td>22.53</td>\n",
              "      <td>4.58</td>\n",
              "      <td>7.52</td>\n",
              "      <td>3.52</td>\n",
              "      <td>31.61</td>\n",
              "      <td>33.85</td>\n",
              "      <td>25691.16</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2  ...        V28     Amount      Class\n",
              "count  284807.00  284807.00  284807.00  ...  284807.00  284807.00  284807.00\n",
              "mean    94813.86       0.00       0.00  ...      -0.00      88.35       0.00\n",
              "std     47488.15       1.96       1.65  ...       0.33     250.12       0.04\n",
              "min         0.00     -56.41     -72.72  ...     -15.43       0.00       0.00\n",
              "25%     54201.50      -0.92      -0.60  ...      -0.05       5.60       0.00\n",
              "50%     84692.00       0.02       0.07  ...       0.01      22.00       0.00\n",
              "75%    139320.50       1.32       0.80  ...       0.08      77.16       0.00\n",
              "max    172792.00       2.45      22.06  ...      33.85   25691.16       1.00\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar_S8NM-MDF7"
      },
      "source": [
        "# Class Imbalance\n",
        "### Notice the ratio of fraudulent to non-fraudulent transaction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_WJRpC_L9aI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a1896f-b16e-4c99-8fd9-33d5c61de808"
      },
      "source": [
        "credit_df[\"Class\"].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90hZMEhIMH33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeef9a04-4fa8-4c07-f1df-1ac3df2bcef2"
      },
      "source": [
        "credit_df[\"Class\"].value_counts(normalize=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.998273\n",
              "1    0.001727\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZSAIiS8fF9"
      },
      "source": [
        "# Random Undersampling\n",
        "To resolve class imbalance , we will use the technique of random undersampling. This will ensure we have equal number of data samples from each label to train the model\n",
        "\n",
        "\n",
        "# Steps to do undersampling based modeling\n",
        "\n",
        "###1) Preserve the original values\n",
        "\n",
        "###2) Scale all values if necessary\n",
        "\n",
        "###3) If minority class values are too less, you'll have to do cross validation. Make sure you are also performing stratified sampling to maintain the original ratio of minority to majority classes.\n",
        "###4) Divide original data into training and testing set. Verify if split is stratified\n",
        "###5)  Now , sample the datset to ensure samples from all classes are equal in number\n",
        "###6) Train the model on undersampled data\n",
        "###7) Test the model on original values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an8Y6zM-shhf",
        "outputId": "96d3aeae-57ef-49f7-ed8c-5bc8c73a297a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Separate features and labels\n",
        "X = credit_df.drop('Class', axis=1)\n",
        "y = credit_df['Class']\n",
        "original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X,y,stratify=y)\n",
        "\n",
        "original_Xtrain = original_Xtrain.values\n",
        "original_Xtest = original_Xtest.values\n",
        "original_ytrain = original_ytrain.values\n",
        "original_ytest = original_ytest.values\n",
        "\n",
        "# See if both the train and test label distribution are similarly distributed\n",
        "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
        "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
        "print('-' * 100)\n",
        "\n",
        "print('Label Distributions: \\n')\n",
        "print(train_counts_label/ len(original_ytrain))\n",
        "print(test_counts_label/ len(original_ytest))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Label Distributions: \n",
            "\n",
            "[0.99827251 0.00172749]\n",
            "[0.99827252 0.00172748]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_zepOx97f1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "796d4006-e47b-4efc-c799-11c82dbef4df"
      },
      "source": [
        "  # Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
        "\n",
        "# Lets shuffle the data before creating the subsamples\n",
        "\n",
        "credit_df = credit_df.sample(frac=1)\n",
        "\n",
        "# amount of fraud classes 492 rows.\n",
        "fraud_credit_df = credit_df.loc[credit_df['Class'] == 1]\n",
        "non_fraud_credit_df = credit_df.loc[credit_df['Class'] == 0][:492]\n",
        "\n",
        "normal_distributed_credit_df = pd.concat([fraud_credit_df, non_fraud_credit_df])\n",
        "\n",
        "# Shuffle dataframe rows\n",
        "new_credit_df = normal_distributed_credit_df.sample(frac=1, random_state=42)\n",
        "\n",
        "new_credit_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8627</th>\n",
              "      <td>11650.0</td>\n",
              "      <td>-1.632329</td>\n",
              "      <td>1.842518</td>\n",
              "      <td>2.657462</td>\n",
              "      <td>0.640792</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.411835</td>\n",
              "      <td>0.613857</td>\n",
              "      <td>-2.677508</td>\n",
              "      <td>2.462120</td>\n",
              "      <td>1.837891</td>\n",
              "      <td>1.782939</td>\n",
              "      <td>-2.078721</td>\n",
              "      <td>2.725942</td>\n",
              "      <td>-0.079082</td>\n",
              "      <td>1.082643</td>\n",
              "      <td>-0.830739</td>\n",
              "      <td>0.291485</td>\n",
              "      <td>-0.339479</td>\n",
              "      <td>-0.477342</td>\n",
              "      <td>0.503926</td>\n",
              "      <td>1.060751</td>\n",
              "      <td>-0.458138</td>\n",
              "      <td>-0.014265</td>\n",
              "      <td>0.298393</td>\n",
              "      <td>0.218421</td>\n",
              "      <td>-0.543628</td>\n",
              "      <td>-0.567761</td>\n",
              "      <td>-0.813954</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249963</th>\n",
              "      <td>154657.0</td>\n",
              "      <td>-0.679521</td>\n",
              "      <td>4.672553</td>\n",
              "      <td>-6.814798</td>\n",
              "      <td>7.143500</td>\n",
              "      <td>0.928654</td>\n",
              "      <td>-1.873013</td>\n",
              "      <td>-2.306689</td>\n",
              "      <td>0.993702</td>\n",
              "      <td>-4.944054</td>\n",
              "      <td>-5.576419</td>\n",
              "      <td>5.783654</td>\n",
              "      <td>-6.117704</td>\n",
              "      <td>0.614165</td>\n",
              "      <td>-12.451499</td>\n",
              "      <td>0.427152</td>\n",
              "      <td>-2.255854</td>\n",
              "      <td>-2.128027</td>\n",
              "      <td>0.706765</td>\n",
              "      <td>1.093826</td>\n",
              "      <td>0.872006</td>\n",
              "      <td>0.566849</td>\n",
              "      <td>-0.321691</td>\n",
              "      <td>-0.281325</td>\n",
              "      <td>-1.120256</td>\n",
              "      <td>-0.073394</td>\n",
              "      <td>0.553530</td>\n",
              "      <td>0.760542</td>\n",
              "      <td>0.386742</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188276</th>\n",
              "      <td>127899.0</td>\n",
              "      <td>2.100563</td>\n",
              "      <td>-0.707363</td>\n",
              "      <td>-1.175133</td>\n",
              "      <td>-0.751382</td>\n",
              "      <td>-0.605782</td>\n",
              "      <td>-0.398639</td>\n",
              "      <td>-1.029384</td>\n",
              "      <td>0.058659</td>\n",
              "      <td>-0.225570</td>\n",
              "      <td>0.241193</td>\n",
              "      <td>1.392186</td>\n",
              "      <td>-0.046240</td>\n",
              "      <td>0.203876</td>\n",
              "      <td>-1.942436</td>\n",
              "      <td>-0.339714</td>\n",
              "      <td>1.871824</td>\n",
              "      <td>1.108779</td>\n",
              "      <td>0.054154</td>\n",
              "      <td>0.487817</td>\n",
              "      <td>0.079625</td>\n",
              "      <td>0.289454</td>\n",
              "      <td>0.856235</td>\n",
              "      <td>0.129602</td>\n",
              "      <td>0.667618</td>\n",
              "      <td>-0.163149</td>\n",
              "      <td>-0.144249</td>\n",
              "      <td>0.020715</td>\n",
              "      <td>-0.013606</td>\n",
              "      <td>19.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30314</th>\n",
              "      <td>35866.0</td>\n",
              "      <td>-2.044489</td>\n",
              "      <td>3.368306</td>\n",
              "      <td>-3.937111</td>\n",
              "      <td>5.623120</td>\n",
              "      <td>-3.079232</td>\n",
              "      <td>-1.253474</td>\n",
              "      <td>-5.778880</td>\n",
              "      <td>1.707428</td>\n",
              "      <td>-4.467103</td>\n",
              "      <td>-6.067798</td>\n",
              "      <td>3.839788</td>\n",
              "      <td>-8.277841</td>\n",
              "      <td>1.493915</td>\n",
              "      <td>-8.416681</td>\n",
              "      <td>0.792298</td>\n",
              "      <td>-7.862659</td>\n",
              "      <td>-14.570837</td>\n",
              "      <td>-5.185386</td>\n",
              "      <td>2.414390</td>\n",
              "      <td>1.112028</td>\n",
              "      <td>1.483594</td>\n",
              "      <td>0.834311</td>\n",
              "      <td>-0.148486</td>\n",
              "      <td>0.001669</td>\n",
              "      <td>-0.038996</td>\n",
              "      <td>0.389526</td>\n",
              "      <td>1.300236</td>\n",
              "      <td>0.549940</td>\n",
              "      <td>7.61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234574</th>\n",
              "      <td>148028.0</td>\n",
              "      <td>-1.053840</td>\n",
              "      <td>4.362801</td>\n",
              "      <td>-6.023534</td>\n",
              "      <td>5.304534</td>\n",
              "      <td>1.480738</td>\n",
              "      <td>-2.193821</td>\n",
              "      <td>-1.530817</td>\n",
              "      <td>0.626857</td>\n",
              "      <td>-4.037021</td>\n",
              "      <td>-6.285424</td>\n",
              "      <td>3.536145</td>\n",
              "      <td>-7.959628</td>\n",
              "      <td>-1.673429</td>\n",
              "      <td>-12.457999</td>\n",
              "      <td>-0.213885</td>\n",
              "      <td>-1.424131</td>\n",
              "      <td>-3.243686</td>\n",
              "      <td>0.059956</td>\n",
              "      <td>-1.802332</td>\n",
              "      <td>0.531574</td>\n",
              "      <td>0.397954</td>\n",
              "      <td>-0.945402</td>\n",
              "      <td>-0.376138</td>\n",
              "      <td>-0.220480</td>\n",
              "      <td>0.264003</td>\n",
              "      <td>0.048935</td>\n",
              "      <td>0.847220</td>\n",
              "      <td>0.531932</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2  ...       V28  Amount  Class\n",
              "8627     11650.0 -1.632329  1.842518  ... -0.813954   10.00      0\n",
              "249963  154657.0 -0.679521  4.672553  ...  0.386742    0.77      1\n",
              "188276  127899.0  2.100563 -0.707363  ... -0.013606   19.95      0\n",
              "30314    35866.0 -2.044489  3.368306  ...  0.549940    7.61      1\n",
              "234574  148028.0 -1.053840  4.362801  ...  0.531932    0.00      1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHZM93GfMZM7"
      },
      "source": [
        "#  \n",
        "#  Build a Gradient Boosting Model\n",
        "###  \n",
        "\n",
        "In this section we'll do k-fold cross validation and use gradient boosting for the prediction algorithm.We'll build our own cross validation loop for gradient boosting.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0drd_sAMMI_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c53741c-4d44-4e71-bdb4-d2cfd4b5c156"
      },
      "source": [
        "# break into features and labels\n",
        "# break into features and labels\n",
        "xy_array = new_credit_df.values\n",
        "x_array = xy_array[:,0:-1]\n",
        "y_array = xy_array[:, -1]\n",
        "print(x_array.shape, y_array.shape) #check the shape to see if it makes sense\n",
        "\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_array,y_array,test_size=0.1,stratify=y_array)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10) #use StratifiedKFold package to define data splits for fold\n",
        "skf.get_n_splits(x_train, y_train)\n",
        "\n",
        "print(skf)\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(984, 30) (984,)\n",
            "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwjhn7beMkYt"
      },
      "source": [
        "params = {'max_depth': 6,\n",
        "         'n_estimators': 500,\n",
        "         'learning_rate': 0.07,\n",
        "         'objective': 'binary:logistic',\n",
        "         'eval_metric': 'error',\n",
        "         'alpha': 5,\n",
        "         'nthread': 5,\n",
        "         'verbosity': 1}\n",
        "\n",
        "         \n",
        "results_list = []\n",
        "for train_index, val_index in skf.split(x_train, y_train):\n",
        "    x_tr, x_val = x_train[train_index, :], x_train[val_index, :]\n",
        "    #print(x_tr.shape)\n",
        "    y_tr, y_val = y_train[train_index], y_train[val_index]\n",
        "    # xgb_dmat = xgb.DMatrix(x_tr, label=y_tr)\n",
        "    #print(1)\n",
        "    model = xgb.XGBClassifier(**params, use_label_encoder=False)\n",
        "    model.fit(x_tr, y_tr, eval_set=[(x_tr, y_tr), (x_val, y_val)],eval_metric='error', verbose=False)\n",
        "    results = model.evals_result()\n",
        "    results_list.append(results)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ-6hqm7MwA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "68f577ad-06b6-422b-c95a-d431db146998"
      },
      "source": [
        "tr_avg = [sum([results_list[j]['validation_0']['error'][i] for j in range(10)])/10 for \n",
        "          i in range(len(results_list[0]['validation_0']['error']))]\n",
        "\n",
        "val_avg = [sum([results_list[j]['validation_1']['error'][i] for j in range(10)])/10 for \n",
        "          i in range(len(results_list[0]['validation_1']['error']))]\n",
        "\n",
        "plt.plot(tr_avg)\n",
        "plt.plot(val_avg)\n",
        "plt.title('train and validation performance versus number of trees')\n",
        "plt.xlabel('number of trees')\n",
        "plt.ylabel('error')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m6ZMmCPMzFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b925a40b-407e-4144-c8c8-b54a4663ed3c"
      },
      "source": [
        "te_probs_gbm = model.predict_proba(original_Xtest)\n",
        "prob1 = [x[1] for x in te_probs_gbm] #linear model returns prob of both binary outcomes\n",
        "\n",
        "#threshold at 0.5\n",
        "y_te_05 = [int(x + 0.5) for x in prob1]\n",
        "y_te_75 = [int(x + 0.25) for x in prob1]\n",
        "y_te_25 = [int(x + 0.75) for x in prob1]\n",
        "\n",
        "conf_mat05 = confusion_matrix(original_ytest, y_te_05)\n",
        "conf_mat75 = confusion_matrix(original_ytest, y_te_75)\n",
        "conf_mat25 = confusion_matrix(original_ytest, y_te_25)\n",
        "\n",
        "print('confusion matrix with 0.5 threshold \\n', conf_mat05)\n",
        "print('confusion matrix with 0.75 threshold \\n', conf_mat75)\n",
        "print('confusion matrix with 0.25 threshold \\n', conf_mat25)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix with 0.5 threshold \n",
            " [[68645  2434]\n",
            " [    2   121]]\n",
            "confusion matrix with 0.75 threshold \n",
            " [[69643  1436]\n",
            " [    2   121]]\n",
            "confusion matrix with 0.25 threshold \n",
            " [[66988  4091]\n",
            " [    1   122]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9O1jFKGM2is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd2b774-91a6-4ea2-cbad-41a07d32b22e"
      },
      "source": [
        "predicted_y = model.predict(x_test)\n",
        "print(precision_score(predicted_y, y_test))\n",
        "print(recall_score(predicted_y, y_test))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.82\n",
            "0.9534883720930233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOKCd_yJM5kc"
      },
      "source": [
        "##  \n",
        "##  Feature importance\n",
        "\n",
        "The dataframe below shows numerical values indicating which variable xgboost relied upon most heavily in making predictions of heart attach.  The list below shows them in order of most important to least.  \n",
        "\n",
        "1. defect severity (thal, 0.271)\n",
        "2. chest pain (cp, 0.228)\n",
        "3. slope of the exercise ST segment (slope, 0.149)\n",
        "4. number of major vessels colored in flouroscopy (ca, 0.145)\n",
        "5. degree of exercise induced angina (exang, 0.111)\n",
        "\n",
        "The rest of the variables are an order of magnitude less important.  Compare these to what penalized linear regression ranked at the most important features.  You'll see that there is agreement between the two lists for several of the variables.  One exception is thalach, which penalized regression relied upon, but gradient boosting ignored.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru1ag5g_M8Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "a5617d12-b5e3-4793-d1fb-f350f5de7485"
      },
      "source": [
        "columns = new_credit_df.columns\n",
        "\n",
        "feature_importance_df = pd.DataFrame.from_dict(dict(zip(columns, model.feature_importances_)), orient='index')\n",
        "display(feature_importance_df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>0.028343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>0.006067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>0.008095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>0.040648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>0.010212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>0.021633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>0.021586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>0.012951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>0.015690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>0.041485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>0.015980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>0.034273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>0.013411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>0.533072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>0.006923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>0.013923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>0.020247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>0.015036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>0.009380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>0.011510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>0.018247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>0.009341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>0.014975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>0.004272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>0.012682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>0.010443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>0.004436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>0.016993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <td>0.014148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0\n",
              "Time    0.014000\n",
              "V1      0.028343\n",
              "V2      0.006067\n",
              "V3      0.008095\n",
              "V4      0.040648\n",
              "V5      0.010212\n",
              "V6      0.021633\n",
              "V7      0.021586\n",
              "V8      0.012951\n",
              "V9      0.015690\n",
              "V10     0.041485\n",
              "V11     0.015980\n",
              "V12     0.034273\n",
              "V13     0.013411\n",
              "V14     0.533072\n",
              "V15     0.006923\n",
              "V16     0.013923\n",
              "V17     0.020247\n",
              "V18     0.015036\n",
              "V19     0.009380\n",
              "V20     0.011510\n",
              "V21     0.018247\n",
              "V22     0.009341\n",
              "V23     0.014975\n",
              "V24     0.004272\n",
              "V25     0.012682\n",
              "V26     0.010443\n",
              "V27     0.004436\n",
              "V28     0.016993\n",
              "Amount  0.014148"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}